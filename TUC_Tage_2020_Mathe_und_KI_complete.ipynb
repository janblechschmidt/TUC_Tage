{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Willkommen zu den TUCtagen 2020\n",
    "---\n",
    "## Mathematik als Schlüssel zur KI: Ziffernerkennung mittels Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wer das ganze selbst ausprobieren will, findet in dem Github-Verzeichnis \n",
    "\n",
    "https://github.com/janblechschmidt/TUC_Tage\n",
    "\n",
    "dieses Notebook und eine Anleitung, wie ihr es starten und ausprobieren könnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Wir starten damit, eine bekannte Bibliothek im Bereich des maschinellen Lernens zu laden: Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIEDQv7kZF6V"
   },
   "outputs": [],
   "source": [
    "# Delete this\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes laden wir uns den MNIST-Datensatz herunter.\n",
    "Er besteht aus handschriftlichen Ziffern von 0 bis 9 und enthält 60.000 grauwertige Trainingsbilder der Größe 28x28, und zusätzlich 10.000 Testbilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns einmal die Daten an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this\n",
    "print('Typ von x_train: {}'.format(type(x_train)))\n",
    "print('Shape von x_train: {}'.format(x_train.shape))\n",
    "x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versuchen wir mal, die Daten etwas schöner darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this\n",
    "import matplotlib.pyplot as plt\n",
    "i = 10\n",
    "plt.imshow(x_train[i], cmap='Greys')\n",
    "print('Die dargestellte Ziffer ist eine {}'.format(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Zielstellung\n",
    "\n",
    "Unser Ziel ist es einen Algorithmus zu entwickeln der ein Bild der Größe 28 x 28 Pixel als Eingabe bekommt und diesem eine Ziffer von 0 bis 9 zuweist.\n",
    "\n",
    "**Datenbereich**: $\\{ 0, 1, \\ldots, 255 \\}^{28 \\times 28}$\n",
    "\n",
    "**Wertebereich**: $\\{0, 1, \\ldots , 9\\}$\n",
    "\n",
    "Mathematisch gesprochen suchen wir eine Funktion, die die Abbildung\n",
    "\n",
    "$$ \n",
    "f : \\text{Bild} \\mapsto \\text{Ziffer}\n",
    "$$\n",
    "\n",
    "realisiert, also\n",
    "\n",
    "$$\n",
    "f : \\{0, 1, \\ldots, 255\\}^{28 \\times 28} \\to \\{0, 1, \\ldots , 9\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie sieht die Funktion $f$ aus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuronale Netze versuchen in vielen Fällen nichts anderes, als komplexe Zusammenhänge zu approximieren.\n",
    "Es besteht aus mehreren Schichten, auch *layers* genannt, die über eine Verkettung bzw. Hintereinanderausführung miteinander verbunden sind.\n",
    "\n",
    "### Schematische Darstellung eines Neuronalen Netzes\n",
    "![Einfaches Feedforward Neural Net](./pictures/FNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabei ist jede Schicht mit jeweils ihrer nächsten Schicht vollständig verbunden. Jede Abbildung zwischen zwei Schichten\\Layers besteht dabei aus zwei Schritten:\n",
    "1. *Propagation*: Um die Werte der *Neuronen* in der ersten Schicht zu berechnen rechnet man\n",
    "\n",
    "$$\n",
    "\t(W^{(1)})^\\top x^{(0)} + b^{(1)}\n",
    "\t= \n",
    "\t\\begin{bmatrix}\n",
    "\t\tw_{1,1}^{(1)}\n",
    "\t\t&\n",
    "\t\tw_{2,1}^{(1)}\n",
    "\t\t&\n",
    "\t\tw_{3,1}^{(1)}\n",
    "\t\t\\\\\n",
    "\t\tw_{1,2}^{(1)}\n",
    "\t\t&\n",
    "\t\tw_{2,2}^{(1)}\n",
    "\t\t&\n",
    "\t\tw_{3,2}^{(1)}\n",
    "\t\t\\\\\n",
    "\t\tw_{1,3}^{(1)}\n",
    "\t\t&\n",
    "\t\tw_{2,3}^{(1)}\n",
    "\t\t&\n",
    "\t\tw_{3,3}^{(1)}\n",
    "\t\t\\\\\n",
    "\t\tw_{1,4}^{(1)}\n",
    "\t\t&\n",
    "\t\tw_{2,4}^{(1)}\n",
    "\t\t&\n",
    "\t\tw_{3,4}^{(1)}\n",
    "\t\t\\\\\n",
    "\t\\end{bmatrix}\n",
    "\t\\begin{pmatrix}\n",
    "\t\tx^{(0)}_1\n",
    "\t\t\\\\\n",
    "\t\tx^{(0)}_2\n",
    "\t\t\\\\\n",
    "\t\tx^{(0)}_3\n",
    "\t\\end{pmatrix}\n",
    "\t+\n",
    "\t\\begin{pmatrix}\n",
    "\t\tb^{(1)}_1\n",
    "\t\t\\\\\n",
    "\t\tb^{(1)}_2\n",
    "\t\t\\\\\n",
    "\t\tb^{(1)}_3\n",
    "\t\t\\\\\n",
    "\t\tb^{(1)}_4\n",
    "\t\\end{pmatrix}\n",
    "    =: \n",
    "\t\\begin{pmatrix}\n",
    "\t\tz^{(1)}_1\n",
    "\t\t\\\\\n",
    "\t\tz^{(1)}_2\n",
    "\t\t\\\\\n",
    "\t\tz^{(1)}_3\n",
    "\t\t\\\\\n",
    "\t\tz^{(1)}_4\n",
    "\t\\end{pmatrix}  \n",
    "$$\n",
    "\n",
    "2. *Activation*: Anschließend wenden wir eine nichtlineare Aktivierungsfunktion $\\sigma^{(1)}$ auf jedes $z^{(1)}_j$ an und erhalten so $x^{(1)}_j$, d.h.\n",
    "\n",
    "$$\n",
    "\t\\begin{pmatrix}\n",
    "\t\tx^{(1)}_1\n",
    "\t\t\\\\\n",
    "\t\tx^{(1)}_2\n",
    "\t\t\\\\\n",
    "\t\tx^{(1)}_3\n",
    "\t\t\\\\\n",
    "\t\tx^{(1)}_4\n",
    "\t\\end{pmatrix}\n",
    "    = \n",
    "    \t\\begin{pmatrix}\n",
    "\t\t\\sigma^{(1)}(z^{(1)}_1)\n",
    "\t\t\\\\\n",
    "\t\t\\sigma^{(1)}(z^{(1)}_2)\n",
    "\t\t\\\\\n",
    "\t\t\\sigma^{(1)}(z^{(1)}_3)\n",
    "\t\t\\\\\n",
    "\t\t\\sigma^{(1)}(z^{(1)}_4)\n",
    "\t\\end{pmatrix}  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Der Kern des Trainings eines neuronalen Netzes besteht darin, die unbekannten Parameter $w_{i,j}$ und $b_j$ möglichst gut zu bestimmen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bekanntestes Beispiel einer Aktivierungsfunktion ist die sogenannte ReLU-Funktion (für Rectified Linear Unit)\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\max \\{ 0 , z \\}.\n",
    "$$\n",
    "\n",
    "## Wie sieht diese Funktion aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this\n",
    "import numpy as np\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "z = np.linspace(-3,3,100)\n",
    "plt.plot(z, relu(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Definition eines Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst laden wir einige Funktionen..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... und initialisieren unser Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als erstes ziehen wir der Einfachheit halber die Bilder, die eigentlich zweidimensional sind, in die Länge.\n",
    "Obwohl wir hierbei wichtige Nachbarschaftsinformationen zwischen Pixeln wegwerfen reicht es immer noch aus, um ein anständigen Klassifizierer zu trainieren.\n",
    "\n",
    "**Hinweis**: Wie das ganze mit richtigen Farbbildern geht, lernt Ihr im Kurs *Optimierung im Maschinellen Lernen*.\n",
    "\n",
    "**Beispiel**:\n",
    "$$\n",
    "\\text{Flatten} \n",
    "\\begin{pmatrix} 1 & 2 \\\\\n",
    "3 & 4\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this\n",
    "model.add(Flatten(input_shape=(28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Dimension unseres Inputlayers ist also $28 \\times 28 = 784$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes fügen wir ein *hidden layer* mit 128 Neuronen ein.\n",
    "Dem Beispiel von oben folgend ergibt das\n",
    "$784 \\times 128 + 128 = 100.480$ \n",
    "Unbekannte.\n",
    "\n",
    "*Hinweis*: Das können wir auch mit der Funktion `model.count_params()` herausfinden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this\n",
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser *output layer* ist 10-dimensional, da wir uns hier für die übliche 0-1-Kodierung entscheiden, die häufig in der Klassifizierung verwendet wird.\n",
    "\n",
    "Dabei wird eine Ziffer von 0 bis 9 durch einen Vektor der Länge 10 darstellt, welcher genau an einer Stelle eine Eins und sonst Nullen enthält, also\n",
    "\n",
    "$$\n",
    "'0' = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix},\n",
    "\\quad\n",
    "'1' = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix},\n",
    "\\quad\n",
    "'2' = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n",
    "\\quad \\cdots \\quad\n",
    "'9' = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete this\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt kommen also nochmal\n",
    "$128 \\times 10 + 10 = 1290$\n",
    "unbekannte Parameter dazu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Zusammen ergibt das {} unbekannte Parameter.'.format(model.count_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt haben wir ein einfaches Modell für unsere Funktion $f$ definiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Grundidee maschinellen Lernens\n",
    "\n",
    "1. Wir starten damit, die 101.770 unbekannten Parameter zufällig zu wählen.\n",
    "2. Anschließend zeigen wir unserem Neuronalen Netz einzeln oder häppchenweise die Bilder aus unserem Trainingsdatensatz `x_train`, lassen das Modell die Ziffer vorhersagen und vergleichen diese Vorhersage mit der tatsächlichen Ziffer.\n",
    "3. Abhängig davon, passen wir die Gewichte systematisch an, um beim nächsten mal eine bessere Klassifikation zu erreichen, also mehr Ziffern richtig zu erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir mit dem Training starten können, benötigen wir noch eine *Loss function*.\n",
    "Eine solche Funktion ist in der Regel ein Maß dafür, wie nah unsere aktuelle Modellvorhersage am tatsächlichen Wert liegt.\n",
    "Damit sagt sie unserem Algorithmus, ob er gut oder schlecht klassifiziert hat.\n",
    "\n",
    "Ohne näher darauf einzugehen, verwenden wir die folgende *Loss function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt fügen wir alles zusammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwW3USTStB8l"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_func,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wie das alles im Detail funktioniert, lernt Ihr bei uns im Mathematik- und Data Science Studium!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend können wir unser Modell mit den Trainingsdaten trainieren (**Jetzt wird tatsächlich gerechnet, und zwar viel!**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18666,
     "status": "ok",
     "timestamp": 1591263674684,
     "user": {
      "displayName": "Jan Blechschmidt",
      "photoUrl": "",
      "userId": "13838644228180744811"
     },
     "user_tz": -120
    },
    "id": "BYhog9L_tF1m",
    "outputId": "210257ab-a9a4-4a01-ffbf-8ae6545efa10"
   },
   "outputs": [],
   "source": [
    "# Delete this\n",
    "model.fit(x_train, y_train, batch_size = 128, epochs = 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man an dem Wert `accuracy` ablesen kann, klassifiziert unser Modell in mehr als 90 % der Fälle die Ziffer korrekt.\n",
    "\n",
    "Schauen wir mal, wie sich das Modell bei Daten schlägt, mit denen es nicht trainiert wurde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1591263689341,
     "user": {
      "displayName": "Jan Blechschmidt",
      "photoUrl": "",
      "userId": "13838644228180744811"
     },
     "user_tz": -120
    },
    "id": "jRehjOBXtHgN",
    "outputId": "551bf06f-869d-4c9b-bd3c-d3d4a3411ec4"
   },
   "outputs": [],
   "source": [
    "# Delete this\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier erreichen wir eine korrekte Klassifizierung in über 90 % der Fälle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am Ende dieses Teils wollen wir uns noch kurz ein paar Beispiele für Ziffern anschauen, die falsch klassifiziert wurden.\n",
    "Wir können diese mit den folgenden Code-Zeilen rausfinden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "wrong_index = np.where(np.argmax(model.predict(x_test), axis=1) != y_test)[0]\n",
    "\n",
    "for j in np.random.randint(0,len(wrong_index),10):\n",
    "    i = wrong_index[j]\n",
    "    y_i = y_test[i]\n",
    "    y_model = np.argmax(model.predict(x_test[i:i+1]))\n",
    "    plt.imshow(x_test[i], cmap = 'Greys')\n",
    "    plt.pause(0.01)\n",
    "    print('Das Modell sagt {} voraus.'.format(y_model))\n",
    "    print('In Wahrheit ist es eine {}.'.format(y_i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warum ist Mathematik der beste Einstieg in die Welt der KI?\n",
    "\n",
    "Auch wenn hier hauptsächlich Programmieren zu erkennen war, fußt das maschinellen Lernen auf mathematischen Verfahren, zu deren Weiterentwicklung und solider Anwendung eine fundierte Mathematikausbildung notwendig ist.\n",
    "\n",
    "### Im Bachelorstudium Mathematik lernt ihr \n",
    "\n",
    "- mathematischen Grundlagen kennen, die auch im maschinellen Lernen von besonderer Bedeutung sind (Lineare Algebra, Numerik, Optimierung, Stochastik)\n",
    "- die Umsetzung mathematischer Verfahren in modernen Programmiersprachen\n",
    "- eine mathematische Herangehensweise an Probleme\n",
    "\n",
    "### Im anschließenden Masterstudium Data Science lernt ihr\n",
    "\n",
    "- wie, und vor allem warum, die eben vorgestellten Algorithmen funktionieren\n",
    "- wir ihr Algorithmen des maschinellen Lernens, z.B. neuronale Netze,  selbst implementiert, auch ohne Bibliotheken wie Tensorflow (Google) oder PyTorch (Facebook)\n",
    "- weitere Anwendungen in den Bereichen Regression, Klassifizierung und Reinforcement Learning kennen"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOis4iVwPer27y9JjmaFXb8",
   "collapsed_sections": [],
   "name": "TUC_Tage_NNs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
